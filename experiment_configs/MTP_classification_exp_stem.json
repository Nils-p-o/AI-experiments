{
    "architecture": "Money_former_MLA_DINT_cog_attn_MTP",
    "d_model": 64,
    "nhead": 2,
    "head_dim": 32,
    "qk_rope_dim": 16,
    "num_layers": 4,
    "d_ff": 64,
    "kv_compression_dim": 16,
    "q_compression_dim": 32,
    "seq_len": 3,
    "stem_seq_len": 21,
    "batch_size": 32,
    "bias": false,
    "indices_to_predict": [1, 2],
    "unique_inputs_ratio": [0, 1],
    "input_features": 0,
    "tickers": ["AAPL","^GSPC", "MSFT", "INTC", "NVDA", "AMZN"],
    "prediction_type": "classification",
    "down_up_loss_weight": 1.0,
    "lr": 10e-4,
    "muon_lr": 0.005,
    "dropout": 0.25,
    "weight_decay": 0.0,
    "warmup_steps": 1000,
    "t_0": 4000,
    "t_mult": 1.5,
    "lr_mult": 0.5,
    "t_total": 5000,
    "scheduler_type": "cosine_restarts",
    "optimizer": "adam",
    "aux_optimizer": "adamw",
    "n_noisy_copies": 0,
    "noise_factor": 0.05,
    "num_classes": 3,
    "classification_threshold": 0.01,
    "include_sep_in_loss": false,
    "use_global_seperator": true,
    "seed": 0,
    "dtype":"fp32",
    "dataset":"Money",
    "type": "",
    "extra_descriptor":"",
    "experiment_notes": "normed feats, global sep, full attn cuz we cool like that, hand picked data, class imbalance weights, exp add cost from optim, trying stem, denser + 10 time kernel + 1 layer of 10 kernel 2d block",
    "folder_name": "testing/class/class_imb_exp_no_cost_stem/",
    "reload_data": false
}